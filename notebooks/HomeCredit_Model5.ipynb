{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit - Gradient Boosting\n",
    "This model is based on [light GBM model](https://lightgbm.readthedocs.io). Some additional feature engineering is performed. For brevity, these are in a separate utils python class. These currenlty extract the data from the other data sources performing aggregations, encondings etc. then merging with the training / test data sets. The engineered data is then fed to the gradient boosting model. Data is split into cross folds and an ROC score calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from pre_process import *\n",
    "from lightgbm_utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init some useful dirs\n",
    "current_dir = os.getcwd()\n",
    "DATA_HOME_DIR = current_dir+'/../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pre, df_test_pre, y = load_train_test_data(DATA_HOME_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 121)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = load_data_dummies(df_train_pre, df_test_pre)\n",
    "df_train, df_test = append_poly_feature(in_dir=DATA_HOME_DIR, df_train=df_train, df_test=df_test)\n",
    "df_train, df_test = append_bureau_data(in_dir=DATA_HOME_DIR, df_train=df_train, df_test=df_test)\n",
    "df_train, df_test = append_previous_applications(in_dir=DATA_HOME_DIR, df_train=df_train, df_test=df_test)\n",
    "df_train, df_test = append_pos_data(in_dir=DATA_HOME_DIR, df_train=df_train, df_test=df_test)\n",
    "df_train, df_test = append_credit_card_data(in_dir=DATA_HOME_DIR, df_train=df_train, df_test=df_test)\n",
    "df_train, df_test = append_installments_data(in_dir=DATA_HOME_DIR, df_train=df_train, df_test=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 831)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 831)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data\n",
    "Run algorithm using cross folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in df_train.columns if f not in ['SK_ID_CURR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True)#, random_state=42) # TODO Remove random seed - only for testing consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "Now run the light GBM model using the cross folds. First the model. \n",
    "\n",
    "TODO: Plugin optunity here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyper parameters\n",
    "EARLY_STOPPING_ROUNDS = 250\n",
    "args = {\n",
    "    \"n_estimators\": 4000,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 30,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"subsample\": 0.9,\n",
    "    \"max_depth\": 6,\n",
    "    \"max_bin\": 1024,\n",
    "    \"num_iterations\": 1000,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    \"min_split_gain\": 0.01,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"silent\": -1,\n",
    "    \"verbose\": -1,\n",
    "   # \"objective\": \"regression\",\n",
    "   # \"metric\": \"\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_log_loss\",\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_freq\": 15,\n",
    "    \"lambda_l1\": 0.0,\n",
    "    \"lambda_l2\": 0.0,\n",
    "    \"min_gain_to_split\": 0.0,\n",
    "    \"feature_fraction\": 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lighgbm file provides a utility class to run a cross fold / lightgbm model. See docs of that method for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lsmith\\appdata\\local\\conda\\conda\\envs\\homecredit\\lib\\site-packages\\lightgbm\\engine.py:102: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds.\n",
      "[100]\ttraining's auc: 0.785565\tvalid_1's auc: 0.764575\n",
      "[200]\ttraining's auc: 0.808956\tvalid_1's auc: 0.77656\n",
      "[300]\ttraining's auc: 0.824786\tvalid_1's auc: 0.781211\n",
      "[400]\ttraining's auc: 0.837411\tvalid_1's auc: 0.783129\n",
      "[500]\ttraining's auc: 0.848305\tvalid_1's auc: 0.784292\n",
      "[600]\ttraining's auc: 0.858255\tvalid_1's auc: 0.784882\n",
      "[700]\ttraining's auc: 0.867474\tvalid_1's auc: 0.785221\n",
      "[800]\ttraining's auc: 0.875767\tvalid_1's auc: 0.785839\n",
      "[900]\ttraining's auc: 0.882787\tvalid_1's auc: 0.785732\n",
      "[1000]\ttraining's auc: 0.888979\tvalid_1's auc: 0.785764\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's auc: 0.888979\tvalid_1's auc: 0.785764\n",
      "Fold  1 AUC : 0.785764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lsmith\\appdata\\local\\conda\\conda\\envs\\homecredit\\lib\\site-packages\\lightgbm\\engine.py:102: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds.\n",
      "[100]\ttraining's auc: 0.785746\tvalid_1's auc: 0.767342\n",
      "[200]\ttraining's auc: 0.809581\tvalid_1's auc: 0.77807\n",
      "[300]\ttraining's auc: 0.825679\tvalid_1's auc: 0.781999\n",
      "[400]\ttraining's auc: 0.838473\tvalid_1's auc: 0.784082\n",
      "[500]\ttraining's auc: 0.850154\tvalid_1's auc: 0.785059\n",
      "[600]\ttraining's auc: 0.859744\tvalid_1's auc: 0.785903\n",
      "[700]\ttraining's auc: 0.868447\tvalid_1's auc: 0.786204\n",
      "[800]\ttraining's auc: 0.875588\tvalid_1's auc: 0.786564\n",
      "[900]\ttraining's auc: 0.882851\tvalid_1's auc: 0.78688\n",
      "[1000]\ttraining's auc: 0.889706\tvalid_1's auc: 0.786947\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's auc: 0.889706\tvalid_1's auc: 0.786947\n",
      "Fold  2 AUC : 0.786947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lsmith\\appdata\\local\\conda\\conda\\envs\\homecredit\\lib\\site-packages\\lightgbm\\engine.py:102: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds.\n",
      "[100]\ttraining's auc: 0.786586\tvalid_1's auc: 0.763858\n",
      "[200]\ttraining's auc: 0.810096\tvalid_1's auc: 0.775464\n",
      "[300]\ttraining's auc: 0.825705\tvalid_1's auc: 0.779768\n",
      "[400]\ttraining's auc: 0.838133\tvalid_1's auc: 0.781896\n",
      "[500]\ttraining's auc: 0.849128\tvalid_1's auc: 0.782914\n",
      "[600]\ttraining's auc: 0.858523\tvalid_1's auc: 0.783588\n",
      "[700]\ttraining's auc: 0.867028\tvalid_1's auc: 0.783994\n",
      "[800]\ttraining's auc: 0.875251\tvalid_1's auc: 0.784416\n",
      "[900]\ttraining's auc: 0.882202\tvalid_1's auc: 0.784165\n",
      "[1000]\ttraining's auc: 0.889305\tvalid_1's auc: 0.784331\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's auc: 0.889305\tvalid_1's auc: 0.784331\n",
      "Fold  3 AUC : 0.784331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lsmith\\appdata\\local\\conda\\conda\\envs\\homecredit\\lib\\site-packages\\lightgbm\\engine.py:102: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds.\n",
      "[100]\ttraining's auc: 0.785648\tvalid_1's auc: 0.76379\n",
      "[200]\ttraining's auc: 0.809027\tvalid_1's auc: 0.775583\n",
      "[300]\ttraining's auc: 0.824207\tvalid_1's auc: 0.780109\n",
      "[400]\ttraining's auc: 0.836938\tvalid_1's auc: 0.782852\n",
      "[500]\ttraining's auc: 0.848238\tvalid_1's auc: 0.784222\n",
      "[600]\ttraining's auc: 0.858148\tvalid_1's auc: 0.785483\n",
      "[700]\ttraining's auc: 0.866898\tvalid_1's auc: 0.786237\n",
      "[800]\ttraining's auc: 0.875078\tvalid_1's auc: 0.786634\n",
      "[900]\ttraining's auc: 0.882281\tvalid_1's auc: 0.786718\n",
      "[1000]\ttraining's auc: 0.889547\tvalid_1's auc: 0.787082\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's auc: 0.889547\tvalid_1's auc: 0.787082\n",
      "Fold  4 AUC : 0.787082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lsmith\\appdata\\local\\conda\\conda\\envs\\homecredit\\lib\\site-packages\\lightgbm\\engine.py:102: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds.\n",
      "[100]\ttraining's auc: 0.785321\tvalid_1's auc: 0.765754\n",
      "[200]\ttraining's auc: 0.809128\tvalid_1's auc: 0.778211\n",
      "[300]\ttraining's auc: 0.825089\tvalid_1's auc: 0.78268\n",
      "[400]\ttraining's auc: 0.837232\tvalid_1's auc: 0.784952\n",
      "[500]\ttraining's auc: 0.84837\tvalid_1's auc: 0.786159\n",
      "[600]\ttraining's auc: 0.858011\tvalid_1's auc: 0.787317\n",
      "[700]\ttraining's auc: 0.86689\tvalid_1's auc: 0.787714\n",
      "[800]\ttraining's auc: 0.873872\tvalid_1's auc: 0.788258\n",
      "[900]\ttraining's auc: 0.880798\tvalid_1's auc: 0.788474\n",
      "[1000]\ttraining's auc: 0.887541\tvalid_1's auc: 0.788715\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's auc: 0.887541\tvalid_1's auc: 0.788715\n",
      "Fold  5 AUC : 0.788715\n",
      "Overall AUC score 0.786547\n"
     ]
    }
   ],
   "source": [
    "df_fold_preds_train, df_fold_preds_test, df_feature_importance = \\\n",
    "    run_lightgbm_model(df_train, df_test, y, folds, feats, early_stopping=EARLY_STOPPING_ROUNDS, args_dict=args)\n",
    "                       #save_model=True, file_prefix=\"m1_nl35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"num_leaves\"]=64\n",
    "args[\"max_depth\"]=7\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fold_preds_train, df_fold_preds_test, df_feature_importance = \\\n",
    "    run_lightgbm_model(df_train, df_test, y, folds, feats, early_stopping=EARLY_STOPPING_ROUNDS, args_dict=args)\n",
    "                       #save_model=True, file_prefix=\"m1_nl35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 4000, 'learning_rate': 0.03, 'num_leaves': 30, 'colsample_bytree': 0.8, 'subsample': 0.9, 'max_depth': 6, 'max_bin': 1024, 'num_iterations': 1000, 'min_data_in_leaf': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'min_split_gain': 0.01, 'min_child_weight': 2, 'silent': -1, 'verbose': -1, 'objective': 'binary', 'metric': 'binary_log_loss', 'bagging_fraction': 0.9, 'bagging_freq': 15, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0, 'feature_fraction': 1.0, 'boosting': 'dart', 'drop_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#args[\"num_leaves\"]=64\n",
    "args[\"boosting\"]=\"dart\"\n",
    "args[\"drop_rate\"]=0.1\n",
    "args[\"learning_rate\"]=0.03\n",
    "EARLY_STOPPING_ROUNDS=200\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lsmith\\appdata\\local\\conda\\conda\\envs\\homecredit\\lib\\site-packages\\lightgbm\\engine.py:102: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.761537\tvalid_1's auc: 0.751174\n",
      "[200]\ttraining's auc: 0.766409\tvalid_1's auc: 0.754385\n",
      "[300]\ttraining's auc: 0.774974\tvalid_1's auc: 0.760211\n",
      "[400]\ttraining's auc: 0.783584\tvalid_1's auc: 0.764976\n",
      "[500]\ttraining's auc: 0.793979\tvalid_1's auc: 0.77101\n",
      "[600]\ttraining's auc: 0.800346\tvalid_1's auc: 0.773916\n",
      "[700]\ttraining's auc: 0.806392\tvalid_1's auc: 0.77587\n"
     ]
    }
   ],
   "source": [
    "df_fold_preds_train, df_fold_preds_test, df_feature_importance = \\\n",
    "    run_lightgbm_model(df_train, df_test, y, folds, feats, early_stopping=EARLY_STOPPING_ROUNDS, args_dict=args)\n",
    "                       #save_model=True, file_prefix=\"m1_nl35\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lsmith\\appdata\\local\\conda\\conda\\envs\\homecredit\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_submission = df_test[['SK_ID_CURR']]\n",
    "df_submission['TARGET'] = df_fold_preds_test\n",
    "df_submission.to_csv('lgbm_submission3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
