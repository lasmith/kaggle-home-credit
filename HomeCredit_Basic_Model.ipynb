{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "# from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "# from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "#from keras.regularizers import l2, activity_l2, l1, activity_l1\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init some useful dirs\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data/'\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "test_path = DATA_HOME_DIR + ''\n",
    "results_path=DATA_HOME_DIR + 'results/'\n",
    "train_path=DATA_HOME_DIR + ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path+\"application_train.csv\")\n",
    "df_test  = pd.read_csv(test_path+\"application_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "First lets get the subset of columns to encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to add missing dummies in test set\n",
    "def fix_missing_cols(in_train, in_test):\n",
    "    missing_cols = set( in_train.columns ) - set( in_test.columns )\n",
    "    # Add a missing column in test set with default value equal to 0\n",
    "    for c in missing_cols:\n",
    "        in_test[c] = 0\n",
    "    # Ensure the order of column in the test set is in the same order than in train set\n",
    "    in_test = in_test[in_train.columns]\n",
    "    return in_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SK_ID_CURR',\n",
    " 'NAME_CONTRACT_TYPE',\n",
    " 'CODE_GENDER',\n",
    " 'FLAG_OWN_CAR',\n",
    " 'FLAG_OWN_REALTY',\n",
    " 'NAME_TYPE_SUITE',\n",
    " 'NAME_INCOME_TYPE',\n",
    " 'NAME_EDUCATION_TYPE',\n",
    " 'NAME_FAMILY_STATUS',\n",
    " 'NAME_HOUSING_TYPE'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now one hot encode. Ideally this would cover all the variations in the underlying data set (not just from the sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_enc = pd.get_dummies(df_train[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( df_train_enc, df_train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246008, 42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246008, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_layers = 42\n",
    "fd_layers = in_layers*2\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(fd_layers, input_dim=in_layers, activation='relu'))\n",
    "model.add(Dense(int((fd_layers/2)), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 84)                3612      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 42)                3570      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 42)                168       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 43        \n",
      "=================================================================\n",
      "Total params: 7,393\n",
      "Trainable params: 7,309\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roc_callback import *\n",
    "roc_cb = roc_callback(training_data=(x_train, y_train),validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "246008/246008 [==============================] - 7s 27us/step - loss: 0.2854 - acc: 0.9191\n",
      "roc-auc: 0.4979 - roc-auc_val: 0.4974                                                                                                    \n",
      "Epoch 2/10\n",
      "246008/246008 [==============================] - 6s 24us/step - loss: 0.2839 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 3/10\n",
      "246008/246008 [==============================] - 6s 25us/step - loss: 0.2840 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 4/10\n",
      "246008/246008 [==============================] - 6s 24us/step - loss: 0.2833 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 5/10\n",
      "246008/246008 [==============================] - 6s 25us/step - loss: 0.2838 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 6/10\n",
      "246008/246008 [==============================] - 6s 25us/step - loss: 0.2844 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 7/10\n",
      "246008/246008 [==============================] - 6s 25us/step - loss: 0.2842 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 8/10\n",
      "246008/246008 [==============================] - 6s 25us/step - loss: 0.2840 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 9/10\n",
      "246008/246008 [==============================] - 6s 25us/step - loss: 0.2838 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 10/10\n",
      "246008/246008 [==============================] - 6s 25us/step - loss: 0.2842 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc13248080>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=batch_size, callbacks=[roc_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "246008/246008 [==============================] - 6s 26us/step - loss: 0.2838 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 2/5\n",
      "246008/246008 [==============================] - 6s 26us/step - loss: 0.2839 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 3/5\n",
      "246008/246008 [==============================] - 6s 26us/step - loss: 0.2844 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 4/5\n",
      "246008/246008 [==============================] - 6s 26us/step - loss: 0.2842 - acc: 0.9192\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "Epoch 5/5\n",
      "246008/246008 [==============================] - 6s 26us/step - loss: 0.2838 - acc: 0.9192: \n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc13a0bc50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=batch_size, callbacks=[roc_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
